<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dart | Shailen Tuli's blog]]></title>
  <link href="http://shailen.github.com/blog/categories/dart/atom.xml" rel="self"/>
  <link href="http://shailen.github.com/"/>
  <updated>2013-01-01T13:21:26-08:00</updated>
  <id>http://shailen.github.com/</id>
  <author>
    <name><![CDATA[Shailen Tuli]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[setting up continuous integration for dart using drone.io]]></title>
    <link href="http://shailen.github.com/blog/2012/12/31/setting-up-continuous-integration-for-dart-using-drone-io/"/>
    <updated>2012-12-31T14:58:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/31/setting-up-continuous-integration-for-dart-using-drone-io</id>
    <content type="html"><![CDATA[<h2>Creating a dummy project</h2>

<p>I created a very simple project, <code>droneDemo</code>, to show how to set up Continuous Integration
on drone.io for Dart projects. The code can be found <a href="https://github.com/shailen/droneDemo">here on Github</a>.</p>

<p><code>droneDemo</code> defines just two methods, <code>add()</code> and <code>multiply()</code>. These
can be found in <code>lib/</code>. Tests for these methods can be found in <code>test/</code>. The
<code>pubspec.yaml</code> file needs to declare a <code>unittest</code> dependency for these tests to
work.</p>

<p>This is about as simple a project as you can have and there is little need for
explanation. But it is worth delving into 2 points:</p>

<p>1) You should add <code>packages</code> to your <code>.gitignore</code>. This is to tell <code>git</code> not to
commit the <code>symlinks</code> created by <code>pub</code> to version control. These symlinks are
meaningful in the context of your filesystem but will trip drone.io.</p>

<p>If you already started your demo project and ended up with the symlinks, remove
them.</p>

<p>2) drone.io needs a way to run all your tests. So far, Dart does not ship with a
test runner, so you'll have to cobble together something yourself.</p>

<p>Here's what I did: my tests live in 2 different files, <code>test/add_test.dart</code> and
<code>test/multiply_test.dart</code>. I declared both files as libraries (see the <code>library add_test;</code>
and the <code>library multiply_test;</code> declaration at the top of each file) and
<code>import</code>ed  components from them into <code>test/test_runner.dart</code>.</p>

<p>   import "package:unittest/unittest.dart";
   import "add_test.dart" as add_test;
   import "multiply_test.dart" as multiply_test;</p>

<p>   void main() {</p>

<pre><code> add_test.main();
 multiply_test.main();
</code></pre>

<p>   }</p>

<p>So, calling <code>dart test/add_test.dart</code> or <code>dart test/multiply_test.dart</code> runs
only one test; calling <code>dart/test_runner.dart</code> runs both the tests.</p>

<p>With this out of the way, we can shift our attention to drone.io.</p>

<h2>Drone.io: Basic Setup</h2>

<p>Set up account at <code>https://drone.io/signup</code>.</p>

<p>On your <code>dashboard</code>, click on the <code>New Project</code> on the top right.</p>

<p>Pick <code>Dart</code> as the project language.</p>

<p>Pick <code>Git</code> as your Repository type.</p>

<p>Add the project name (I added <code>droneDemo</code>).</p>

<p>Add the Repository URL (mine was <code>https://github.com/shailen/droneDemo.git</code>).
Make sure your github repo is set to use the <code>http</code> method, not the <code>ssh</code> method.</p>

<p>Press <code>Create</code>.</p>

<h2>Configuring your Build</h2>

<p>After you press <code>Create</code>, you will be redirected to the <code>script/config</code> page.
Here, you will have to tell drone.io how to run your tests.</p>

<p>In the <code>Commands</code> section, type the following:</p>

<pre><code>pub install
dart test/test_runner.dart
</code></pre>

<p>Remember <code>test/test_runner.dart</code> was our consolidating test runner? This is
where the trouble we went through sewing our tests together pays off.</p>

<p>Press <code>Save</code> and when you get the message that tells you the build was
successfully saved, press the blue <code>Build Now</code> button at the top.</p>

<p>A popup will appear with a <code>Build Output</code> link.  Click that link.</p>

<p>Voila! You are swimming in a sea of green!</p>

<p><img src="/images/drone_io_success.png"></p>

<p>My build output can be seen at: <code>https://drone.io/shailen/droneDemo/1</code></p>

<h2>Setting up Continuous Build</h2>

<p>Click on <code>settings</code> for your <code>drone.io</code> project</p>

<p>Click on <code>General</code> in the left column. You will see a couple of links under <code>Build Hooks</code>. Copy the top one.</p>

<p>Now, go back to your project on <code>github</code>. Mine is at <code>https://github.com/shailen/droneDemo</code>.</p>

<p>Click on <code>Settings</code>.</p>

<p>Click on <code>Service Hooks</code> (left column).</p>

<p>Click on the <code>WebHook Urls</code> link at the top.</p>

<p>Paste the <code>build hook</code> you had copied earlier in the text input box provided
and press <code>Update Settings</code>.</p>

<p>From now on, every time you commit to your project on github, drone.io will run
all your tests.</p>

<p>I changed one of my tests so that it was failing and pushed to github. No
surprise, the build now show <code>Failed</code> (<code>https://drone.io/shailen/droneDemo</code>).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Randomness in Dart: nextBool(), nextInt(), and nextDouble()]]></title>
    <link href="http://shailen.github.com/blog/2012/12/10/random-dart-nextbool-nextint-and-nextdouble/"/>
    <updated>2012-12-10T14:36:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/10/random-dart-nextbool-nextint-and-nextdouble</id>
    <content type="html"><![CDATA[<p>The <code>Random</code> class in <code>dart:math</code> contains 3 methods, <code>nextBool()</code>, <code>nextInt()</code>
and <code>nextDouble()</code>. To use <code>Random</code>, you will need a <code>import 'dart:math</code> in your
code.</p>

<h2>nextBool()</h2>

<p>simply returns <code>true</code> or <code>false</code> at random. Here is a little
function, <code>randUpcase()</code> that demonstrates <code>randBool()</code> use. <code>randUpcase()</code>
takes a string as an argument, and converts each character in the string to
uppercase if random.nextBool() is <code>true</code> and leaves it untouched if it is
<code>false</code>.</p>

<pre><code>String randUpcase(String s) {
  Random random = new Random();
  List&lt;String&gt; chars = s.split('');
  return Strings.join(chars.map(
    (char) =&gt; random.nextBool() ? char.toUpperCase() : char), '');
}
</code></pre>

<p>And here is some sample usage:</p>

<pre><code>var herbs = ["parsley", "sage", "rosemary", "thyme"];
print(herbs.map((herb) =&gt; randUpcase(herb))); // [pARslEY, SaGE, roSEMaRY, tHYME]
</code></pre>

<h2>nextInt()</h2>

<p>takes a <code>max</code> int argument and generates a positive int between 0 (inclusive) and <code>max</code>, exclusive.</p>

<p>To generate a random int within a range, you can do something like this:</p>

<pre><code>int randRange(int min, int max) {
  var random = new Random();
  return min + random.nextInt(max - min);
}
</code></pre>

<p>You can also use <code>nextInt()</code> to randomly shuffle a list (using the familiar
Fisher-Yates-Knuth algorithm):</p>

<pre><code>List shuffle(List items) {
  var random = new Random();
  for (var i = items.length - 1; i &gt; 0; i--) {
    var j = random.nextInt(i);
    var temp = items[i];
    items[i] = items[j];
    items[j] = temp;
  }
  return items;
}
</code></pre>

<p>You can use it like this:</p>

<pre><code>var items = ["fee", "fi", "fo", "fum", "smell", "Englishman"];
print(shuffle(items)); // [fo, smell, fum, Englishman, fee, fi]
</code></pre>

<h2>nextDouble()</h2>

<p>generates a random floating point value distributed between 0.0
and 1.0. Here is a little function to simulate a biased coin toss; the <code>percent</code>
argument alters the percent a coin will return heads ('H'). This is pretty much cribbed from
<a href="http://stackoverflow.com/questions/477237/how-do-i-simulate-flip-of-biased-coin-in-python">this discussion on Stack Overflow</a>:</p>

<pre><code>String flip(num percent) {
  Random random = new Random();
  return random.nextDouble() &lt; percent ? 'H' : 'T';
}
</code></pre>

<p>And here is some code to test that it works:</p>

<pre><code>int n = 1000;
int heads = 0;
for (var i = 0; i &lt; 1000; i++) {
  if(flip(.20) == "H") heads++;
}
print(heads/n); // 0.209, 0.196, etc.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Only Some of Your Dart Tests with filterTests()]]></title>
    <link href="http://shailen.github.com/blog/2012/12/07/running-only-some-of-your-tests/"/>
    <updated>2012-12-07T10:00:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/07/running-only-some-of-your-tests</id>
    <content type="html"><![CDATA[<p>The Dart <code>unittest</code> library allows you to run just a single test; to do so,
just change the call for that test form <code>test()</code> to <code>solo_test()</code>.</p>

<p>Another way to run a subset of your tests is by using the <code>filterTests()</code>
function. <code>filterTests()</code> takes a String or a RegExp argument and matches
it against each test description; if the description matches, the test
runs, otherwise, it doesn't.</p>

<p>Before you use <code>filterTests()</code>, you need to disable the automatic running of
tests (set <code>autoStart</code> to false) and ensure that the your configuration is
initialized.</p>

<p>You can do this by creating a custom configuration:</p>

<pre><code>import "package:unittest/unittest.dart";
import "package:args/args.dart";

class FilterTests extends Configuration {
  get autoStart =&gt; false;
}

void useFilteredTests() {
  configure(new FilterTests());
  ensureInitialized();  
}
</code></pre>

<p>Then, you can call <code>useFilteredTests()</code> in your <code>main()</code>, define all your
tests, call <code>filteredTests()</code> with a string or regexp argument and run your
tests using <code>runTests()</code>:</p>

<pre><code>void main() {
  useFilteredTests();

  // your tests go here

  filterTests(some_string_or_regexp);
  runTests();
}
</code></pre>

<p>Here is a little working example:</p>

<pre><code>void main() {
  useFilteredTests();

  test("one test", () {
    expect(1, equals(1));
  }); 

  test("another test", () {
    expect(2, equals(2));
  });

  test("and another", () {
    expect(3, equals(3));
  });

  filterTests('test');
  // filterTests('another');

  runTests();
}
</code></pre>

<p><code>filterTests('test')</code> will run the first 2 tests; <code>filterTests('another')</code> will
run the last 2 tests.</p>

<p>It is easy to make this <em>considerably</em> more useful by getting the argument to
<code>filterTests()</code> from the command line. That way, you can control what subset of
tests to run without having to change the code in your test suite. Here is a
slightly expanded version of the same example:</p>

<pre><code>void main() {
  useFilteredTests();
  ArgParser argParser = new ArgParser();
  Options options = new Options();
  ArgResults results = argParser.parse(options.arguments);
  List&lt;String&gt; args = results.rest; // get the args from the command line

  test("one test", (){
    expect(1, equals(1));
  }); 

  test("another test", (){
    expect(2, equals(2));
  });

  test("and another", (){
    expect(3, equals(3));
  });

  // we add a group() to show how we can easily run just the tests
  // contained in it
  group("foo", () {
    test("this", (){
      expect('bar', equals('bar'));
    }); 

    test("that", (){
      expect('baz', equals('baz'));
    });
  });

  if (!args.isEmpty) {
    filterTests(args[0]);
  }
  runTests();
}
</code></pre>

<p>You can run the tests from the command line by using the</p>

<pre><code>`dart name_of_file.dart [keyword]`
</code></pre>

<p>syntax. If the keyword is <code>this</code>, only one test will run. If the keyword is
<code>foo</code>, all tests in the <code>group()</code> with the description of <code>foo</code> will run.
If you do not provide a keyword, all 5 tests will run.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dart: Customizing Unittest Run Output]]></title>
    <link href="http://shailen.github.com/blog/2012/12/06/customizing-the-look-of-your-test-run-output/"/>
    <updated>2012-12-06T14:57:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/06/customizing-the-look-of-your-test-run-output</id>
    <content type="html"><![CDATA[<p><code>unittest</code> provides a default configuration that determines the
content and appearance of the output from running your tests. In addition, the
package provides fancier configurations for running tests in the browser, or on
the VM.</p>

<p>But suppose you want to customize the test run output? Maybe you are an ardent
Test Driven Development (TDD) hacker, and want to have your test output be
in sync with TDD Red-Green-Refactor workflow (passing tests in green, failing
tests in red); maybe you want a green "." printed to the command line for every
passing test (you don't care for all the "PASS: ..." messages that the default
configuration gives you), and a red 'F' printed for every failing test, with
more details about the failures in the summary. You also want the ouput to
list the file where the tests being run are located and you want to know how
long it takes to run all your tests.</p>

<p>To do all this, you need to extend the default <code>Configuration</code> class (see
<code>unittest/src/config.dart</code>) and customize your environment by passing an
instance of that class to <code>configure()</code> as an argument.
A <code>Configuration</code> has several functions that get called at different stages of
the testing process:</p>

<pre><code>onInit(), when the test framework is initialized
onStart(), before the first test is run
onTestStart(), when a test starts running
onTestResult(), upon the completion of each test
onDone(), when all tests are done
</code></pre>

<p>and you can override all of these.</p>

<p>Let's extend <code>Configuration</code> and begin by adding a few constants to help with the
presentation:</p>

<pre><code>class ColorTestRunner extends Configuration {
  const String NEUTRAL_COLOR = "\u001b[33;34m"; // blue
  const String PASS_COLOR = "\u001b[33;32m";    // green
  const String FAIL_COLOR = "\u001b[33;31m";    // red
  const String RESET_COLOR = "\u001b[33;0m";

  ...
}
</code></pre>

<p>We will prefix our failing output with <code>FAIL_COLOR</code>, passing output
with <code>PASS_COLOR</code> and use <code>RESET_COLOR</code> to revert back to the user's settings.
We will use <code>NEUTRAL_COLOR</code> to print a small introduction and the summary.</p>

<p>We are now ready to start filling out our <code>ColorTestRunner</code> class. The
<code>onInit()</code> of <code>Configuration</code> is empty; let's add a little introduction that
prints the name of the file containing the tests:</p>

<pre><code>void onInit() { 
  print(NEUTRAL_COLOR);
  Options options = new Options();  
  print("Running tests for ${options.script}");
  print(RESET_COLOR);
}
</code></pre>

<p>Now let's move on to <code>onStart()</code>. This is called after <code>onInit()</code> but before
the first test is run. In the default <code>Configuration</code>, this prints the
<code>unittest-suite-wait-for-done</code> message. We pushed our custom message in
the <code>onInit()</code>, so we don't need another message here. But this would be a
good place to start running the stopwatch for timing our tests:</p>

<pre><code>Stopwatch stopwatch = new Stopwatch();
void onStart() =&gt; stopwatch.start();
</code></pre>

<p><code>Configuration</code> defines the twin <code>onTestStart()</code> and <code>onTestResult()</code> functions
that basically define which test is currently being run:</p>

<pre><code>void onTestStart(TestCase testCase) {
  currentTestCase = testCase;
}

void onTestResult(TestCase testCase) {
  currentTestCase = null;
}
</code></pre>

<p>We don't need to tinker with <code>onTestRun()</code>, but we'll override <code>onTestResult()</code> to
output the green <code>.</code> or red <code>F</code> for passing and failing tests, respectively:</p>

<pre><code>void onTestResult(TestCase testCase) {
  var color = testCase.result == PASS ? PASS_COLOR : FAIL_COLOR;
  stdout.writeString("${color}${testCase.result == PASS ? '.' : 'F'}$RESET_COLOR");
  currentTestCase = null;
}
</code></pre>

<p>The <code>onDone()</code> function is where <code>Configuration</code> does the heavy lifting: it
outputs the status and description of each test as well as the error messages
and stack traces for failing tests. Then, it provides summary informtion for
the test run. We'll just skip over the passing tests and color-code our
summary (it will be red if even a single test fails). Then, we will output
the total time taken for the tests to run (remember the stopwatch we started in
<code>onStart()</code>?.</p>

<p>With a little bit of refactoring, and some additional formatting added to the
output, here is what the script looks like:</p>

<pre><code>library colorTestRunner;

import 'package:unittest/unittest.dart';
import 'dart:io';

/// Overrides default Configuration to provide colorful command line
/// output when tests are run. Loosely based on RSpec (https://www.relishapp.com/rspec).
/// Outputs green (passing) "." and red (failing) "F" characters as tests are running. 
/// If there are failing tests, provides detailed error report in red.
/// Provides a short summary.
class ColorTestRunner extends Configuration {
  const String NEUTRAL_COLOR = "\u001b[33;34m"; // blue
  const String PASS_COLOR = "\u001b[33;32m";    // green
  const String FAIL_COLOR = "\u001b[33;31m";    // red
  const String RESET_COLOR = "\u001b[33;0m";
  const int BORDER_LENGTH = 80;

  Stopwatch stopwatch = new Stopwatch();

  void onInit() =&gt; _printResultHeader();
  void onStart() =&gt; stopwatch.start();

  void onTestResult(TestCase testCase) {
    var color = testCase.result == PASS ? PASS_COLOR : FAIL_COLOR;
    _colorPrint(color, testCase);
    currentTestCase = null;
  }

  void onDone(int passed, int failed, int errors, List&lt;TestCase&gt; testCases,
              String uncaughtError) {
    stopwatch.stop();

    _printFailingTestInfo(testCases);
    _printSummary(passed, failed, errors, uncaughtError);
    print("${NEUTRAL_COLOR}Total time = ${stopwatch.elapsedMilliseconds / 1000} seconds.$RESET_COLOR");
  }

  void _printFailingTestInfo(List&lt;TestCase&gt; testCases) {
    print(FAIL_COLOR);
    for (var testCase in testCases) {
      if (testCase.result != PASS) {
        print("${testCase.result.toUpperCase()}: ${testCase.description}");

        if (testCase.message != '') {
          print(testCase.message);
        }

        if (testCase.stackTrace != null &amp;&amp; testCase.stackTrace != '') {
          print(testCase.stackTrace);
        }

        print(_repeatString(".", BORDER_LENGTH));
      }
    }
    print(RESET_COLOR);
  }

  void _printSummary(int passed, int failed, int errors, String uncaughtError) {
    if (_passed(failed, errors, uncaughtError)) {
      print(PASS_COLOR); 
      print("All $passed tests passed.");
    } else {
      print(FAIL_COLOR); 
      if (_noTestsFound(passed, failed, errors)) {
        print('No tests found.');
      } else if (uncaughtError != null) {
        print("Top-level uncaught error: $uncaughtError");
      } else {
        print("$passed PASSED, $failed FAILED, $errors ERRORS.");
      }
    }
  }

  bool _noTestsFound(int passed, int failed, int errors) {
    return passed == 0 &amp;&amp; failed == 0 &amp;&amp; errors == 0;
  }

  bool _passed(int failed, int errors, String uncaughtError) {
    return failed == 0 &amp;&amp; errors == 0 &amp;&amp; uncaughtError == null;
  }

  void _printResultHeader() {
    print(NEUTRAL_COLOR);
    Options options = new Options();  
    String description = "Running tests for ${options.script}";
    String frame = _repeatString("=", description.length);
    print(frame);
    print(description);
    print(frame);
    print(RESET_COLOR);
  }

  String _repeatString(String str, int times) {
    StringBuffer sb = new StringBuffer();
    for (var i = 0; i &lt; times; i++) {
      sb.add(str);  
    }
    return sb.toString();
  }

  void _colorPrint(String color, TestCase testCase) {
    stdout.writeString("${color}${testCase.result == PASS ? '.' : 'F'}$RESET_COLOR");
  }
}

/// The function that should be called right before the tests.
void useColorTestRunner() {
  configure(new ColorTestRunner());
}
</code></pre>

<p>To use this script, call the <code>useColorTestRunner()</code> just before where you have
defined your tests. Here is a simple use case:</p>

<pre><code>import 'package:unittest/unittest.dart';
import '&lt;path to&gt;/color_test_runner.dart';

num factorial(num n) {
  if (n &lt; 2) {
    return 1;
  } else {
    return n * factorial(n - 1);
  }
}

void main() {
  useColorTestRunner(); // we're using our own configuration

  test("when n is 0", () {   
    expect(factorial(0), equals(1));
  });

  test("when n is 1", () {
    expect(factorial(1), equals(1));
  });

  test("when n is &gt; 1", () {
    expect(factorial(5), equals(120));
  });
}
</code></pre>

<p>Call this from the command line: <code>dart &lt;test file&gt;.dart</code> and your output should
look like this:</p>

<p><img src="/images/passing_tests.png"></p>

<p>Everything is green. Great! But perhaps you were in a hurry and got your <code>0</code> and
<code>1</code> mixed up in the first test:</p>

<pre><code>test("when n is 0", () {   
  expect(factorial(1), equals(0)); // oops....!
});
</code></pre>

<p>If you run the tests now, you'll see:</p>

<p><img src="images/failing_tests.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[using setUp() in your Dart tests]]></title>
    <link href="http://shailen.github.com/blog/2012/11/21/using-setup-in-your-dart-tests/"/>
    <updated>2012-11-21T22:47:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/11/21/using-setup-in-your-dart-tests</id>
    <content type="html"><![CDATA[<p>Take this minimal <code>Point</code> class:</p>

<pre><code>class Point {
  num x;
  num y;
  Point(this.x, this.y);

  num distanceTo(Point other) {
    ...
  }
}
</code></pre>

<p>As you write tests for <code>Point</code>, you will probably want to set up one or more <code>point</code> objects that you can access in each
test. Something like:</p>

<pre><code>void main() {
  group("Point", (){
    setUp((){
      Point p1 = new Point(3, 4);
      Point p2 = new Point(3, 5);
    });
    test("distanceTo()", (){
      expect(p1.distanceTo(p2), equals(...));
    });
  });
}
</code></pre>

<p>Do this and the Editor starts complaining that it cannot make sense of <code>p1</code> or <code>p2</code>. Why?  Remember, <code>setUp()</code> simply calls the function passed
to it before each <code>test()</code> and our code defining <code>p1</code> and <code>p2</code> will therefore run every time. But (and this seems like a Captain Obvious mement) because <code>p1</code> and <code>p2</code>
are local to function called by <code>setUp()</code>, they cannot be accessed from outside that function.  But it takes only very small changes to take care of the access problem:</p>

<pre><code>void main() {
  group("Point", (){
    Point p1;
    Point p2;
    setUp((){
      p1 = new Point(3, 4);
      p2 = new Point(3, 5);
    });
    test("distanceTo()", (){
      expect(p1.distanceTo(p2), equals(34));
    });
  });
});
</code></pre>

<p>Now, the function called by <code>setUp()</code> assigns a value to the already existing <code>p1</code> and <code>p2</code>.</p>
]]></content>
  </entry>
  
</feed>
