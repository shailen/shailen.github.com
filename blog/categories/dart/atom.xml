<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dart | Shailen Tuli's blog]]></title>
  <link href="http://shailen.github.com/blog/categories/dart/atom.xml" rel="self"/>
  <link href="http://shailen.github.com/"/>
  <updated>2012-12-31T17:16:21-08:00</updated>
  <id>http://shailen.github.com/</id>
  <author>
    <name><![CDATA[Shailen Tuli]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Randomness in Dart: nextBool(), nextInt(), and nextDouble()]]></title>
    <link href="http://shailen.github.com/blog/2012/12/10/random-dart-nextbool-nextint-and-nextdouble/"/>
    <updated>2012-12-10T14:36:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/10/random-dart-nextbool-nextint-and-nextdouble</id>
    <content type="html"><![CDATA[<p>The <code>Random</code> class in <code>dart:math</code> contains 3 methods, <code>nextBool()</code>, <code>nextInt()</code>
and <code>nextDouble()</code>. To use <code>Random</code>, you will need a <code>import 'dart:math</code> in your
code.</p>

<h2>nextBool()</h2>

<p>simply returns <code>true</code> or <code>false</code> at random. Here is a little
function, <code>randUpcase()</code> that demonstrates <code>randBool()</code> use. <code>randUpcase()</code>
takes a string as an argument, and converts each character in the string to
uppercase if random.nextBool() is <code>true</code> and leaves it untouched if it is
<code>false</code>.</p>

<pre><code>String randUpcase(String s) {
  Random random = new Random();
  List&lt;String&gt; chars = s.split('');
  return Strings.join(chars.map(
    (char) =&gt; random.nextBool() ? char.toUpperCase() : char), '');
}
</code></pre>

<p>And here is some sample usage:</p>

<pre><code>var herbs = ["parsley", "sage", "rosemary", "thyme"];
print(herbs.map((herb) =&gt; randUpcase(herb))); // [pARslEY, SaGE, roSEMaRY, tHYME]
</code></pre>

<h2>nextInt()</h2>

<p>takes a <code>max</code> int argument and generates a positive int between 0 (inclusive) and <code>max</code>, exclusive.</p>

<p>To generate a random int within a range, you can do something like this:</p>

<pre><code>int randRange(int min, int max) {
  var random = new Random();
  return min + random.nextInt(max - min);
}
</code></pre>

<p>You can also use <code>nextInt()</code> to randomly shuffle a list (using the familiar
Fisher-Yates-Knuth algorithm):</p>

<pre><code>List shuffle(List items) {
  var random = new Random();
  for (var i = items.length - 1; i &gt; 0; i--) {
    var j = random.nextInt(i);
    var temp = items[i];
    items[i] = items[j];
    items[j] = temp;
  }
  return items;
}
</code></pre>

<p>You can use it like this:</p>

<pre><code>var items = ["fee", "fi", "fo", "fum", "smell", "Englishman"];
print(shuffle(items)); // [fo, smell, fum, Englishman, fee, fi]
</code></pre>

<h2>nextDouble()</h2>

<p>generates a random floating point value distributed between 0.0
and 1.0. Here is a little function to simulate a biased coin toss; the <code>percent</code>
argument alters the percent a coin will return heads ('H'). This is pretty much cribbed from
<a href="http://stackoverflow.com/questions/477237/how-do-i-simulate-flip-of-biased-coin-in-python">this discussion on Stack Overflow</a>:</p>

<pre><code>String flip(num percent) {
  Random random = new Random();
  return random.nextDouble() &lt; percent ? 'H' : 'T';
}
</code></pre>

<p>And here is some code to test that it works:</p>

<pre><code>int n = 1000;
int heads = 0;
for (var i = 0; i &lt; 1000; i++) {
  if(flip(.20) == "H") heads++;
}
print(heads/n); // 0.209, 0.196, etc.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Only Some of Your Dart Tests with filterTests()]]></title>
    <link href="http://shailen.github.com/blog/2012/12/07/running-only-some-of-your-tests/"/>
    <updated>2012-12-07T10:00:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/07/running-only-some-of-your-tests</id>
    <content type="html"><![CDATA[<p>The Dart <code>unittest</code> library allows you to run just a single test; to do so,
just change the call for that test form <code>test()</code> to <code>solo_test()</code>.</p>

<p>Another way to run a subset of your tests is by using the <code>filterTests()</code>
function. <code>filterTests()</code> takes a String or a RegExp argument and matches
it against each test description; if the description matches, the test
runs, otherwise, it doesn't.</p>

<p>Before you use <code>filterTests()</code>, you need to disable the automatic running of
tests (set <code>autoStart</code> to false) and ensure that the your configuration is
initialized.</p>

<p>You can do this by creating a custom configuration:</p>

<pre><code>import "package:unittest/unittest.dart";
import "package:args/args.dart";

class FilterTests extends Configuration {
  get autoStart =&gt; false;
}

void useFilteredTests() {
  configure(new FilterTests());
  ensureInitialized();  
}
</code></pre>

<p>Then, you can call <code>useFilteredTests()</code> in your <code>main()</code>, define all your
tests, call <code>filteredTests()</code> with a string or regexp argument and run your
tests using <code>runTests()</code>:</p>

<pre><code>void main() {
  useFilteredTests();

  // your tests go here

  filterTests(some_string_or_regexp);
  runTests();
}
</code></pre>

<p>Here is a little working example:</p>

<pre><code>void main() {
  useFilteredTests();

  test("one test", () {
    expect(1, equals(1));
  }); 

  test("another test", () {
    expect(2, equals(2));
  });

  test("and another", () {
    expect(3, equals(3));
  });

  filterTests('test');
  // filterTests('another');

  runTests();
}
</code></pre>

<p><code>filterTests('test')</code> will run the first 2 tests; <code>filterTests('another')</code> will
run the last 2 tests.</p>

<p>It is easy to make this <em>considerably</em> more useful by getting the argument to
<code>filterTests()</code> from the command line. That way, you can control what subset of
tests to run without having to change the code in your test suite. Here is a
slightly expanded version of the same example:</p>

<pre><code>void main() {
  useFilteredTests();
  ArgParser argParser = new ArgParser();
  Options options = new Options();
  ArgResults results = argParser.parse(options.arguments);
  List&lt;String&gt; args = results.rest; // get the args from the command line

  test("one test", (){
    expect(1, equals(1));
  }); 

  test("another test", (){
    expect(2, equals(2));
  });

  test("and another", (){
    expect(3, equals(3));
  });

  // we add a group() to show how we can easily run just the tests
  // contained in it
  group("foo", () {
    test("this", (){
      expect('bar', equals('bar'));
    }); 

    test("that", (){
      expect('baz', equals('baz'));
    });
  });

  if (!args.isEmpty) {
    filterTests(args[0]);
  }
  runTests();
}
</code></pre>

<p>You can run the tests from the command line by using the</p>

<pre><code>`dart name_of_file.dart [keyword]`
</code></pre>

<p>syntax. If the keyword is <code>this</code>, only one test will run. If the keyword is
<code>foo</code>, all tests in the <code>group()</code> with the description of <code>foo</code> will run.
If you do not provide a keyword, all 5 tests will run.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dart: Customizing Unittest Run Output]]></title>
    <link href="http://shailen.github.com/blog/2012/12/06/customizing-the-look-of-your-test-run-output/"/>
    <updated>2012-12-06T14:57:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/12/06/customizing-the-look-of-your-test-run-output</id>
    <content type="html"><![CDATA[<p><code>unittest</code> provides a default configuration that determines the
content and appearance of the output from running your tests. In addition, the
package provides fancier configurations for running tests in the browser, or on
the VM.</p>

<p>But suppose you want to customize the test run output? Maybe you are an ardent
Test Driven Development (TDD) hacker, and want to have your test output be
in sync with TDD Red-Green-Refactor workflow (passing tests in green, failing
tests in red); maybe you want a green "." printed to the command line for every
passing test (you don't care for all the "PASS: ..." messages that the default
configuration gives you), and a red 'F' printed for every failing test, with
more details about the failures in the summary. You also want the ouput to
list the file where the tests being run are located and you want to know how
long it takes to run all your tests.</p>

<p>To do all this, you need to extend the default <code>Configuration</code> class (see
<code>unittest/src/config.dart</code>) and customize your environment by passing an
instance of that class to <code>configure()</code> as an argument.
A <code>Configuration</code> has several functions that get called at different stages of
the testing process:</p>

<pre><code>onInit(), when the test framework is initialized
onStart(), before the first test is run
onTestStart(), when a test starts running
onTestResult(), upon the completion of each test
onDone(), when all tests are done
</code></pre>

<p>and you can override all of these.</p>

<p>Let's extend <code>Configuration</code> and begin by adding a few constants to help with the
presentation:</p>

<pre><code>class ColorTestRunner extends Configuration {
  const String NEUTRAL_COLOR = "\u001b[33;34m"; // blue
  const String PASS_COLOR = "\u001b[33;32m";    // green
  const String FAIL_COLOR = "\u001b[33;31m";    // red
  const String RESET_COLOR = "\u001b[33;0m";

  ...
}
</code></pre>

<p>We will prefix our failing output with <code>FAIL_COLOR</code>, passing output
with <code>PASS_COLOR</code> and use <code>RESET_COLOR</code> to revert back to the user's settings.
We will use <code>NEUTRAL_COLOR</code> to print a small introduction and the summary.</p>

<p>We are now ready to start filling out our <code>ColorTestRunner</code> class. The
<code>onInit()</code> of <code>Configuration</code> is empty; let's add a little introduction that
prints the name of the file containing the tests:</p>

<pre><code>void onInit() { 
  print(NEUTRAL_COLOR);
  Options options = new Options();  
  print("Running tests for ${options.script}");
  print(RESET_COLOR);
}
</code></pre>

<p>Now let's move on to <code>onStart()</code>. This is called after <code>onInit()</code> but before
the first test is run. In the default <code>Configuration</code>, this prints the
<code>unittest-suite-wait-for-done</code> message. We pushed our custom message in
the <code>onInit()</code>, so we don't need another message here. But this would be a
good place to start running the stopwatch for timing our tests:</p>

<pre><code>Stopwatch stopwatch = new Stopwatch();
void onStart() =&gt; stopwatch.start();
</code></pre>

<p><code>Configuration</code> defines the twin <code>onTestStart()</code> and <code>onTestResult()</code> functions
that basically define which test is currently being run:</p>

<pre><code>void onTestStart(TestCase testCase) {
  currentTestCase = testCase;
}

void onTestResult(TestCase testCase) {
  currentTestCase = null;
}
</code></pre>

<p>We don't need to tinker with <code>onTestRun()</code>, but we'll override <code>onTestResult()</code> to
output the green <code>.</code> or red <code>F</code> for passing and failing tests, respectively:</p>

<pre><code>void onTestResult(TestCase testCase) {
  var color = testCase.result == PASS ? PASS_COLOR : FAIL_COLOR;
  stdout.writeString("${color}${testCase.result == PASS ? '.' : 'F'}$RESET_COLOR");
  currentTestCase = null;
}
</code></pre>

<p>The <code>onDone()</code> function is where <code>Configuration</code> does the heavy lifting: it
outputs the status and description of each test as well as the error messages
and stack traces for failing tests. Then, it provides summary informtion for
the test run. We'll just skip over the passing tests and color-code our
summary (it will be red if even a single test fails). Then, we will output
the total time taken for the tests to run (remember the stopwatch we started in
<code>onStart()</code>?.</p>

<p>With a little bit of refactoring, and some additional formatting added to the
output, here is what the script looks like:</p>

<pre><code>library colorTestRunner;

import 'package:unittest/unittest.dart';
import 'dart:io';

/// Overrides default Configuration to provide colorful command line
/// output when tests are run. Loosely based on RSpec (https://www.relishapp.com/rspec).
/// Outputs green (passing) "." and red (failing) "F" characters as tests are running. 
/// If there are failing tests, provides detailed error report in red.
/// Provides a short summary.
class ColorTestRunner extends Configuration {
  const String NEUTRAL_COLOR = "\u001b[33;34m"; // blue
  const String PASS_COLOR = "\u001b[33;32m";    // green
  const String FAIL_COLOR = "\u001b[33;31m";    // red
  const String RESET_COLOR = "\u001b[33;0m";
  const int BORDER_LENGTH = 80;

  Stopwatch stopwatch = new Stopwatch();

  void onInit() =&gt; _printResultHeader();
  void onStart() =&gt; stopwatch.start();

  void onTestResult(TestCase testCase) {
    var color = testCase.result == PASS ? PASS_COLOR : FAIL_COLOR;
    _colorPrint(color, testCase);
    currentTestCase = null;
  }

  void onDone(int passed, int failed, int errors, List&lt;TestCase&gt; testCases,
              String uncaughtError) {
    stopwatch.stop();

    _printFailingTestInfo(testCases);
    _printSummary(passed, failed, errors, uncaughtError);
    print("${NEUTRAL_COLOR}Total time = ${stopwatch.elapsedMilliseconds / 1000} seconds.$RESET_COLOR");
  }

  void _printFailingTestInfo(List&lt;TestCase&gt; testCases) {
    print(FAIL_COLOR);
    for (var testCase in testCases) {
      if (testCase.result != PASS) {
        print("${testCase.result.toUpperCase()}: ${testCase.description}");

        if (testCase.message != '') {
          print(testCase.message);
        }

        if (testCase.stackTrace != null &amp;&amp; testCase.stackTrace != '') {
          print(testCase.stackTrace);
        }

        print(_repeatString(".", BORDER_LENGTH));
      }
    }
    print(RESET_COLOR);
  }

  void _printSummary(int passed, int failed, int errors, String uncaughtError) {
    if (_passed(failed, errors, uncaughtError)) {
      print(PASS_COLOR); 
      print("All $passed tests passed.");
    } else {
      print(FAIL_COLOR); 
      if (_noTestsFound(passed, failed, errors)) {
        print('No tests found.');
      } else if (uncaughtError != null) {
        print("Top-level uncaught error: $uncaughtError");
      } else {
        print("$passed PASSED, $failed FAILED, $errors ERRORS.");
      }
    }
  }

  bool _noTestsFound(int passed, int failed, int errors) {
    return passed == 0 &amp;&amp; failed == 0 &amp;&amp; errors == 0;
  }

  bool _passed(int failed, int errors, String uncaughtError) {
    return failed == 0 &amp;&amp; errors == 0 &amp;&amp; uncaughtError == null;
  }

  void _printResultHeader() {
    print(NEUTRAL_COLOR);
    Options options = new Options();  
    String description = "Running tests for ${options.script}";
    String frame = _repeatString("=", description.length);
    print(frame);
    print(description);
    print(frame);
    print(RESET_COLOR);
  }

  String _repeatString(String str, int times) {
    StringBuffer sb = new StringBuffer();
    for (var i = 0; i &lt; times; i++) {
      sb.add(str);  
    }
    return sb.toString();
  }

  void _colorPrint(String color, TestCase testCase) {
    stdout.writeString("${color}${testCase.result == PASS ? '.' : 'F'}$RESET_COLOR");
  }
}

/// The function that should be called right before the tests.
void useColorTestRunner() {
  configure(new ColorTestRunner());
}
</code></pre>

<p>To use this script, call the <code>useColorTestRunner()</code> just before where you have
defined your tests. Here is a simple use case:</p>

<pre><code>import 'package:unittest/unittest.dart';
import '&lt;path to&gt;/color_test_runner.dart';

num factorial(num n) {
  if (n &lt; 2) {
    return 1;
  } else {
    return n * factorial(n - 1);
  }
}

void main() {
  useColorTestRunner(); // we're using our own configuration

  test("when n is 0", () {   
    expect(factorial(0), equals(1));
  });

  test("when n is 1", () {
    expect(factorial(1), equals(1));
  });

  test("when n is &gt; 1", () {
    expect(factorial(5), equals(120));
  });
}
</code></pre>

<p>Call this from the command line: <code>dart &lt;test file&gt;.dart</code> and your output should
look like this:</p>

<p><img src="/images/passing_tests.png"></p>

<p>Everything is green. Great! But perhaps you were in a hurry and got your <code>0</code> and
<code>1</code> mixed up in the first test:</p>

<pre><code>test("when n is 0", () {   
  expect(factorial(1), equals(0)); // oops....!
});
</code></pre>

<p>If you run the tests now, you'll see:</p>

<p><img src="images/failing_tests.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[using setUp() in your Dart tests]]></title>
    <link href="http://shailen.github.com/blog/2012/11/21/using-setup-in-your-dart-tests/"/>
    <updated>2012-11-21T22:47:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/11/21/using-setup-in-your-dart-tests</id>
    <content type="html"><![CDATA[<p>Take this minimal <code>Point</code> class:</p>

<pre><code>class Point {
  num x;
  num y;
  Point(this.x, this.y);

  num distanceTo(Point other) {
    ...
  }
}
</code></pre>

<p>As you write tests for <code>Point</code>, you will probably want to set up one or more <code>point</code> objects that you can access in each
test. Something like:</p>

<pre><code>void main() {
  group("Point", (){
    setUp((){
      Point p1 = new Point(3, 4);
      Point p2 = new Point(3, 5);
    });
    test("distanceTo()", (){
      expect(p1.distanceTo(p2), equals(...));
    });
  });
}
</code></pre>

<p>Do this and the Editor starts complaining that it cannot make sense of <code>p1</code> or <code>p2</code>. Why?  Remember, <code>setUp()</code> simply calls the function passed
to it before each <code>test()</code> and our code defining <code>p1</code> and <code>p2</code> will therefore run every time. But (and this seems like a Captain Obvious mement) because <code>p1</code> and <code>p2</code>
are local to function called by <code>setUp()</code>, they cannot be accessed from outside that function.  But it takes only very small changes to take care of the access problem:</p>

<pre><code>void main() {
  group("Point", (){
    Point p1;
    Point p2;
    setUp((){
      p1 = new Point(3, 4);
      p2 = new Point(3, 5);
    });
    test("distanceTo()", (){
      expect(p1.distanceTo(p2), equals(34));
    });
  });
});
</code></pre>

<p>Now, the function called by <code>setUp()</code> assigns a value to the already existing <code>p1</code> and <code>p2</code>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[grouping dart tests]]></title>
    <link href="http://shailen.github.com/blog/2012/11/20/grouping-dart-tests/"/>
    <updated>2012-11-20T16:02:00-08:00</updated>
    <id>http://shailen.github.com/blog/2012/11/20/grouping-dart-tests</id>
    <content type="html"><![CDATA[<p>Yesterday, we create a simple Dart package with a <code>range</code> library and wrote a couple of tests. Let's pick up
where we left off and add more tests.</p>

<p>We should test that the list returned by <code>range()</code> does not include <code>stop</code> and that an ArgumentError is raised when start >= stop.
Modify your <code>range_test.dart</code> file so that it contains the new tests:</p>

<pre><code>import 'package:unittest/unittest.dart';
import 'package:range/range.dart';

void main() {
  test("range() produces a list that starts at `start`", () {
    expect(range(0, 4)[0], equals(0));
  });

  test ("range() produces a list that stops before `stop`", () {
    expect(range(0, 4).last, equals(3));
  });

  test("range() throws an exception when start &gt; stop", () {
    expect(() =&gt; range(5, 2), throwsA(new isInstanceOf&lt;ArgumentError&gt;()));
  });

  test("range() throws an exception when start == stop", () {
    expect(() =&gt; range(5, 5), throwsA(new isInstanceOf&lt;ArgumentError&gt;()));
  });
}
</code></pre>

<p>Run the tests again. They should all pass. We have doubled our test coverage!</p>

<p>Now, what we have here works fine, but we can improve things a bit. Notice the repetition in the string arguments we pass to
each <code>test()</code> ("range() produces ...", "range() throws ...", etc.)? We should clean that up. Also, we have 4 tests that fall into
2 natural groups: the first two call <code>range()</code> with valid arguments and the last two with invalid arguments. We should arrange
our tests more clearly to reflect this grouping. Finally, there are no tests for the optional <code>step</code> argument. We should add those.
Rewriting our tests, we get:</p>

<pre><code>import 'package:unittest/unittest.dart';
import 'package:range/range.dart';

void main() {
  group("range()", () {
    group("produces a list that", () {
      test("starts at `start`", () {
        expect(range(0, 4)[0], equals(0));
      });

      test ("stops before `stop`", () {
        expect(range(0, 4).last, equals(3));
      });

      test("has consecutive values if no `step` is given", () {
        expect(range(1, 6), equals([1, 2, 3, 4, 5]));
      });

      test("has non-consecutive values with `step` &gt; 1", () {
        expect(range(1, 6, 2), equals([1, 3, 5]));
      });
    });

    group("throws an exception when", () {
      test("start &gt; stop", () {
        expect(() =&gt; range(5, 2), throwsA(new isInstanceOf&lt;ArgumentError&gt;()));
      });

      test("start == stop", () {
        expect(() =&gt; range(5, 5), throwsA(new isInstanceOf&lt;ArgumentError&gt;()));
      });
    });
  });
}
</code></pre>

<p>Much better. We use nested <code>group()</code>s to organize our tests; we pass descriptive string args to each <code>group()</code> to make our intent clear; we get rid
of a lot of repetition.</p>

<p>Let's run our tests again:</p>

<pre><code>unittest-suite-wait-for-done
PASS: range() produces a list that starts at `start`
PASS: range() produces a list that stops before `stop`
PASS: range() produces a list that has consecutive values if no `step` is given
PASS: range() produces a list that has non-consecutive values with `step` &gt; 1
PASS: range() throws an exception when start &gt; stop
PASS: range() throws an exception when start == stop

All 6 tests passed.
unittest-suite-success
</code></pre>
]]></content>
  </entry>
  
</feed>
